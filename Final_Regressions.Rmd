---
title: "Final_Regressions"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = normalizePath("./"))
```


```{r, echo=FALSE}
d = read.xlsx('Final_241_Data_Shared.xlsx')
#d = d[d$Guess_the_Cost <= 2000,]
# load packages 
library(data.table)
library(dplyr)
library(tidyr)
library(foreign)
library(lmtest)
library(sandwich)
library(multiwayvcov)
```


#1. Functions to use
```{r}
standard_conf_int_95 = function(regression, n){
  r = coeftest(regression, vcovHC(regression))
  upper_bound = r[n,1] + 1.96* r[n, 2] 
  lower_bound = r[n,1] -1.96* r[n, 2]
  return (c(lower_bound,upper_bound))
}
```
#deduping/cleaning
```{r deduping}
library(data.table)
# Cleaning out incomplete responses before treament exposures
d <- d[!is.na(d$Track),]
#summary(d)
# Counting occurances of IP address and Geo-codes
d$geo_code <- paste(d$LocationLatitude, d$LocationLongitude)
dt = data.table(d)
dt[, `freq_geo` := .N, by = geo_code]
dt[, `freq_ip` := .N, by = IPAddress]
#class(as.data.frame(dt))
#dt
## Creatig 2 dedupped dataset, one with complete dedup where we do not allow any duplicates in IP or Geo code, and one where we exclude IP dupes, but allow up to 5 dups per geo code
complete_dedup<- dt[dt$freq_ip==1 & dt$freq_geo==1]
#nrow(complete_dedup)
five_or_less_dedup <- dt[dt$freq_ip==1 & dt$freq_geo<=5]
#nrow(five_or_less_dedup)
d<-five_or_less_dedup
```

##Summary/Initial Plots
###All guesses, including high outliers
```{r}
hist(d$Guess_the_Cost[d$Guess_the_Cost<1500],main="All Guesses",breaks=100,xlab= "Guessed cost")
```

```{r}
#hist, includes all cleaned 
hist(d$Guess_the_Cost,main="All conditions",xlab= "Guessed cost", xlim = c(0,100),breaks=1000)
abline(v = mean(d$Guess_the_Cost), col = "blue")
abline(v = median(d$Guess_the_Cost), col = "green")

#formats
par(mfrow=c(1,3),pin=c(2,2))

hist(d$Guess_the_Cost[d$French_Purchasing_Page == 1],main = "French format",xlab= "Guessed cost", xlim = c(0,100),breaks=1000)
abline(v = mean(d$Guess_the_Cost[d$French_Purchasing_Page == 1]), col = "blue")
abline(v = median(d$Guess_the_Cost[d$French_Purchasing_Page == 1]), col = "green")

hist(d$Guess_the_Cost[d$German_Purchasing_Page == 1],main = "German format",xlab= "Guessed cost", xlim = c(0,100),breaks=1000)
abline(v = mean(d$Guess_the_Cost[d$German_Purchasing_Page == 1]), col = "blue")
abline(v = median(d$Guess_the_Cost[d$German_Purchasing_Page == 1]), col = "green")

hist(d$Guess_the_Cost[d$German_Purchasing_Page == 0 & d$French_Purchasing_Page == 0 ],main = "English format", xlab= "Guessed cost", xlim = c(0,100),breaks=1000)
abline(v = median(d$Guess_the_Cost[d$German_Purchasing_Page == 0 & d$French_Purchasing_Page == 0]), col = "green")
abline(v = mean(d$Guess_the_Cost[d$German_Purchasing_Page == 0 & d$French_Purchasing_Page == 0]), col = "blue")

```
```{r}
#hist figures for origin, description, cleaned 
par(mfrow=c(2,2))

#Origins
d_chart=d$Guess_the_Cost[d$US_Origin == 1]
hist(d_chart,main = "US Origin Wine",xlab= "Guessed cost", xlim = c(0,100),breaks=1000)
abline(v = mean(d_chart), col = "blue")
abline(v = median(d_chart), col = "green")

d_chart=d$Guess_the_Cost[d$US_Origin == 0]
hist(d_chart,main = "French Origin Wine",xlab= "Guessed cost", xlim = c(0,100),breaks=1000)
abline(v = mean(d_chart), col = "blue")
abline(v = median(d_chart), col = "green")

#descriptions
d_chart=d$Guess_the_Cost[d$Long_Description == 0]
hist(d_chart,main = "Short Description",xlab= "Guessed cost", xlim = c(0,100),breaks=1000)
abline(v = mean(d_chart), col = "blue")
abline(v = median(d_chart), col = "green")

d_chart=d$Guess_the_Cost[d$Long_Description == 1]
hist(d_chart,main = "Long Description",xlab= "Guessed cost", xlim = c(0,100),breaks=1000)
abline(v = mean(d_chart), col = "blue")
abline(v = median(d_chart), col = "green")
```

```{r}
#with outliers
r = lm(Guess_the_Cost~French_Purchasing_Page + German_Purchasing_Page, data = d)

coeftest(r, vcovHC(r))

(French_95 = standard_conf_int_95(r,'French_Purchasing_Page'))
(German_95 = standard_conf_int_95(r,'German_Purchasing_Page'))

sd(d$Guess_the_Cost[d$French_Purchasing_Page == 1])
sd(d$Guess_the_Cost[d$German_Purchasing_Page == 1])
sd(d$Guess_the_Cost[d$German_Purchasing_Page == 0 & d$French_Purchasing_Page ==0])
```





```{r}
(French_effect = cohen.d(Guess_the_Cost~French_Purchasing_Page, data = d[d$German_Purchasing_Page != 1,]))

(German_effect = cohen.d(Guess_the_Cost~German_Purchasing_Page, data = d[d$French_Purchasing_Page != 1,]))
```
**Effect size is very small for both French and German effect**

```{r}
pwr.t2n.test(n1 = NROW(d[d$German_Purchasing_Page != 1 & d$French_Purchasing_Page != 1,]), n2 = NROW(d[d$French_Purchasing_Page == 1,]), d = .045, sig.level = .05)

pwr.t2n.test(n1 = NROW(d[d$German_Purchasing_Page != 1 & d$French_Purchasing_Page != 1,]), n2 = NROW(d[d$German_Purchasing_Page == 1,]), d = 0.037, sig.level = .05)


```

**Due to the high variance in our Guess the Price outcome, our power for detecting an effect between French and English language was 9.8%, and our power for detecting an effect between German and English language was 8.22%.**

**Gpower says effect size f is 0.022**

```{r}
pwr.1way(k=3, n=400, f=0.1, alpha=0.05) #Aiming for effect size of 0.1 - Power of 88%

pwr.1way(k=3, n=400, f=0.022, alpha=0.05) #Got effect size of 0.022 - Power of 9.6%
```

```{r}
r = lm(Guess_the_Cost~French_Purchasing_Page + German_Purchasing_Page + US_Origin + French_Purchasing_Page * US_Origin + German_Purchasing_Page*US_Origin, data = d)

coeftest(r, vcovHC(r))
```

```{r}
r = lm(Guess_the_Cost~French_Purchasing_Page + German_Purchasing_Page + US_Origin + French_Purchasing_Page * Long_Description + German_Purchasing_Page*Long_Description, data = d)

coeftest(r, vcovHC(r))
```
```{r}
French_cb = lm(French_Purchasing_Page ~ Male + Household_Income + English_as_primary + Drink_Frequency + Cab_Preference + Purchase_Frequency, data = d[d$German_Purchasing_Page != 1,])

summary(French_cb)

German_cb = lm(German_Purchasing_Page ~ Male + Household_Income + English_as_primary + Drink_Frequency + Cab_Preference + Purchase_Frequency, data = d[d$French_Purchasing_Page != 1,])

summary(German_cb)

French_German_cb = lm(French_Purchasing_Page ~ Male + Household_Income + English_as_primary + Drink_Frequency + Cab_Preference + Purchase_Frequency, data = d[d$French_Purchasing_Page == 1 | d$German_Purchasing_Page == 1 ,])

summary(French_German_cb)
```

**p-values greater than .05 for all 3 regressions --> Covariate balance check shows that we cannot reject the null hypothesis that our covariates have no predictive power over our treatment variable**

```{r}
r = lm(Purchase_50 ~French_Purchasing_Page + German_Purchasing_Page, data = d)
coeftest(r, vcovHC(r))

```

```{r}
r = lm(Purchase_35 ~French_Purchasing_Page + German_Purchasing_Page, data = d)
coeftest(r, vcovHC(r))
```

```{r}
r = lm(Purchase_20 ~French_Purchasing_Page + German_Purchasing_Page, data = d)
coeftest(r, vcovHC(r))
```

#Char's regressions- from investigations file
```{r}
DT<-data.table(d)
lm.format<-lm(Guess_the_Cost~French_Purchasing_Page + German_Purchasing_Page,DT)

lm.origin<-lm(Guess_the_Cost~US_Origin,DT)

lm.description<-lm(Guess_the_Cost~Long_Description,DT)

lm.combined<-lm(Guess_the_Cost~French_Purchasing_Page + German_Purchasing_Page + US_Origin + Long_Description,DT)
stargazer(lm.combined,lm.format,lm.origin,lm.description,main="Basic regressions- no covariates", align=TRUE, type="text")

```
###Maybe try RLM here- need to be able to explain it

##Adding in Covariates
```{r}
#NOTE: this cell is ALREADY in writeup
#Process/clean variables- covariates
d<-data.table(d)
#English as primary language
d$English_as_primary<-d[,.(abs(d$English_as_primary-2))]
d$English_as_primary<-as.factor(d$English_as_primary)
#Male: original, male=1, female=2
d$Male<-d[,.(abs(d$Male-2))]
d$Male<-as.factor(d$Male)
#household income- as factor due to <20k, >100k, and do not answer
d$Household_Income<-as.factor(d$Household_Income)
#Other languages- Blank is only English, French 1, German 2, Other 3
#d$Speaks_German<-as.numeric(d[,Other_Language_Spoken %like% "2"])
#d$Speaks_French<-as.numeric(d[,Other_Language_Spoken %like% "1"])
#Drink Frequency- options are not linear 
d$Drink_Frequency<-factor(d$Drink_Frequency)

#Cab preference
d$Cab_Preference<-d[,.(abs(d$Cab_Preference-2))]

#Purchase Frequency- also not linear
d$Purchase_Frequency<-factor(d$Purchase_Frequency)
```

```{r}
#basic covariate model, treatment is format
lm.cv_format<-lm(Guess_the_Cost~French_Purchasing_Page + German_Purchasing_Page + Male + English_as_primary  + Cab_Preference +Household_Income + Drink_Frequency+Purchase_Frequency,d)
lm.cv_origin<-lm(Guess_the_Cost~US_Origin + Male + Household_Income + English_as_primary + Cab_Preference + Drink_Frequency+ Purchase_Frequency,d)
lm.cv_description<-lm(Guess_the_Cost~Long_Description + Male + Household_Income + English_as_primary  + Cab_Preference + Drink_Frequency + Purchase_Frequency,d)

stargazer(lm.cv_format,lm.cv_origin,lm.cv_description,align=TRUE,type="text")
```
###Tracks Saturated model
```{r,include=FALSE}
DT$Track<-factor(DT$Track)
lm.saturated<-lm(Guess_the_Cost~ Track + Male + Household_Income + English_as_primary + Drink_Frequency + Cab_Preference + Purchase_Frequency,DT)
summary(lm.saturated)
```

```{r}
#same origin/format binary
d<-data.table(d)
d$same_format_origin<-rep(0,length(d$French_Purchasing_Page))
d[French_Purchasing_Page==1 & US_Origin==0,same_format_origin :=1]
d[German_Purchasing_Page==0 & French_Purchasing_Page==0 & US_Origin==1,same_format_origin :=1]
#French layout+french wine
d$French_format_wine<-rep(0,length(d$French_Purchasing_Page))
d[French_Purchasing_Page==1 & US_Origin==0,"French_format_wine" :=1]
#English layout + US wine
d$English_format_wine<-rep(0,length(d$French_Purchasing_Page))
d[German_Purchasing_Page==0 & French_Purchasing_Page==0 & US_Origin==1,"English_format_wine" :=1]

#models
lm.same<-lm(Guess_the_Cost ~  same_format_origin + Male  + English_as_primary  + Cab_Preference + Household_Income+ Drink_Frequency + Purchase_Frequency ,d)
#summary(lm.same)
lm.same_indiv<-lm(d$Guess_the_Cost ~ French_format_wine + English_format_wine + Male + Household_Income + English_as_primary + Drink_Frequency + Cab_Preference + Purchase_Frequency,d)
stargazer(lm.same,lm.same_indiv,align=TRUE,type="text")
```


